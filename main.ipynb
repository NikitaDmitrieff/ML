{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6db299ff",
   "metadata": {},
   "source": [
    "## CW Intro to ML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9ddfb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary librairies\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import default_rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10972786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 8)\n"
     ]
    }
   ],
   "source": [
    "# dataset read \n",
    "\n",
    "dataset = np.loadtxt('wifi_db/clean_dataset.txt')\n",
    "\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3e61c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 7)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:,:-1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94b6998e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 7) (1600, 1)\n",
      "(400, 7) (400, 1)\n"
     ]
    }
   ],
   "source": [
    "def read_dataset(filepath):\n",
    "    \"\"\" Read in the dataset from the specified filepath\n",
    "\n",
    "    Args:\n",
    "        filepath (str): The filepath to the dataset file\n",
    "\n",
    "    Returns:\n",
    "        tuple: returns a tuple of (x, y, classes), each being a numpy array. \n",
    "               - x is a numpy array with shape (N, K), \n",
    "                   where N is the number of instances\n",
    "                   K is the number of features/attributes\n",
    "               - y is a numpy array with shape (N, ), and should be integers from 0 to C-1\n",
    "                   where C is the number of classes \n",
    "               - classes : a numpy array with shape (C, ), which contains the \n",
    "                   unique class labels corresponding to the integers in y\n",
    "    \"\"\"\n",
    "\n",
    "    x = []\n",
    "    y_labels = []\n",
    "    dataset = np.loadtxt(filepath)\n",
    "    \n",
    "    x = dataset[:,:-1]\n",
    "    y = dataset[:,-1:]\n",
    "    \n",
    "    classes = np.unique(y)\n",
    "\n",
    "\n",
    "    return (x, y, classes)\n",
    "\n",
    "\n",
    "def split_dataset(x, y, test_proportion, random_generator=default_rng()):\n",
    "    \"\"\" Split dataset into training and test sets, according to the given \n",
    "        test set proportion.\n",
    "    \n",
    "    Args:\n",
    "        x (np.ndarray): Instances, numpy array with shape (N,K)\n",
    "        y (np.ndarray): Class labels, numpy array with shape (N,)\n",
    "        test_proprotion (float): the desired proportion of test examples \n",
    "                                 (0.0-1.0)\n",
    "        random_generator (np.random.Generator): A random generator\n",
    "\n",
    "    Returns:\n",
    "        tuple: returns a tuple of (x_train, x_test, y_train, y_test) \n",
    "               - x_train (np.ndarray): Training instances shape (N_train, K)\n",
    "               - x_test (np.ndarray): Test instances shape (N_test, K)\n",
    "               - y_train (np.ndarray): Training labels, shape (N_train, )\n",
    "               - y_test (np.ndarray): Test labels, shape (N_train, )\n",
    "    \"\"\"\n",
    "\n",
    "    shuffled_indices = random_generator.permutation(len(x))\n",
    "    n_test = round(len(x) * test_proportion)\n",
    "    n_train = len(x) - n_test\n",
    "    x_train = x[shuffled_indices[:n_train]]\n",
    "    y_train = y[shuffled_indices[:n_train]]\n",
    "    x_test = x[shuffled_indices[n_train:]]\n",
    "    y_test = y[shuffled_indices[n_train:]]\n",
    "    return (x_train, x_test, y_train, y_test)\n",
    "\n",
    "\n",
    "\n",
    "(x, y, classes) = read_dataset('wifi_db/clean_dataset.txt')\n",
    "\n",
    "seed = 60012\n",
    "rg = default_rng(seed)\n",
    "x_train, x_test, y_train, y_test = split_dataset(x, y, \n",
    "                                                 test_proportion=0.2, \n",
    "                                                 random_generator=rg)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10f45906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(y_train == 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "63a82c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary functions to compute data in order to make the decision tree\n",
    "\n",
    "\n",
    "\n",
    "def H(y, labels): \n",
    "    \n",
    "    entropy = 0\n",
    "    \n",
    "    \n",
    "    N = x.shape[0]\n",
    "    \n",
    "    for label in labels:\n",
    "        prob = np.count_nonzero(y == label)/N\n",
    "        if prob == 0:\n",
    "            continue\n",
    "        entropy -= prob*np.log2(prob)\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "H(y_train, classes)\n",
    "\n",
    "def remainder(y_left, y_right, labels):\n",
    "    N = y_left.shape[0] + y_right.shape[0]\n",
    "    \n",
    "    rem = (y_left.shape[0]/N)*H(y_left, labels) + (y_right.shape[0]/N)*H(y_right, labels)\n",
    "    \n",
    "    return rem\n",
    "\n",
    "def gain(y_all, y_left, y_right, labels):\n",
    "    return H(y_all, labels) - remainder(y_left, y_right, labels)\n",
    "            \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d461a748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3416331631753122"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gain(y, y_train, y_test, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "245992ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_split(data, labels):\n",
    "    \n",
    "    n_features = len(data[0]) - 1\n",
    "    \n",
    "    best_gain = gain(data[:-1], data[data[:,0]>data[0][0]][:-1], data[data[:,0]<=data[0][0]][:-1], classes)\n",
    "    best_thresh = data[0][0]\n",
    "    best_feat = 0\n",
    "    \n",
    "    for i in range(n_features):\n",
    "        \n",
    "        best_feat_gain = gain(data[:-1], data[data[:,i]>data[i][0]][:-1], data[data[:,i]<=data[i][0]][:-1], classes)\n",
    "        best_feat_thresh = data[i][0]\n",
    "        \n",
    "        for xi in data[:,i]:\n",
    "\n",
    "            right = data[data[:,i]>xi]\n",
    "            left = data[data[:,i]<=xi]\n",
    "            \n",
    "            feat_gain = gain(data[:-1], left[:-1], right[:-1], labels)\n",
    "            \n",
    "            if feat_gain > best_feat_gain:\n",
    "                best_feat_gain = feat_gain\n",
    "                best_feat_thresh = xi\n",
    "                \n",
    "        print(best_feat_gain, best_feat_thresh)      \n",
    "        if best_feat_gain > best_gain:\n",
    "            best_feat = i\n",
    "            best_gain = best_feat_gain\n",
    "            best_thresh = best_feat_thresh\n",
    "            \n",
    "            \n",
    "    right = data[data[:,best_feat] > best_thresh]\n",
    "    left = data[data[:,best_feat] <= best_thresh]\n",
    "    \n",
    "    return best_feat, best_thresh\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "   \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c0953330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9707244042265755 -55.0\n",
      "0.5094277825857527 -56.0\n",
      "0.6518768781318678 -56.0\n",
      "0.9123691914431387 -57.0\n",
      "0.7469761444598508 -63.0\n",
      "0.6955053240632996 -81.0\n",
      "0.6908951549707205 -81.0\n"
     ]
    }
   ],
   "source": [
    "best_feat, best_thresh, right, left = find_split(dataset, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3ca90659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1202 798\n"
     ]
    }
   ],
   "source": [
    "print(len(right), len(left))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "99543682",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9707244042265755 -55.0\n",
      "0.5094277825857527 -56.0\n",
      "0.6518768781318678 -56.0\n",
      "0.9123691914431387 -57.0\n",
      "0.7469761444598508 -63.0\n",
      "0.6955053240632996 -81.0\n",
      "0.6908951549707205 -81.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " -55.0,\n",
       " array([[-42., -53., -62., ..., -65., -69.,   2.],\n",
       "        [-44., -55., -61., ..., -72., -68.,   2.],\n",
       "        [-41., -58., -56., ..., -69., -73.,   2.],\n",
       "        ...,\n",
       "        [-52., -61., -48., ..., -80., -80.,   4.],\n",
       "        [-54., -57., -50., ..., -83., -82.,   4.],\n",
       "        [-54., -46., -48., ..., -84., -85.,   4.]]),\n",
       " array([[-64., -56., -61., ..., -82., -81.,   1.],\n",
       "        [-68., -57., -61., ..., -85., -85.,   1.],\n",
       "        [-63., -60., -60., ..., -85., -84.,   1.],\n",
       "        ...,\n",
       "        [-62., -59., -46., ..., -87., -88.,   4.],\n",
       "        [-62., -58., -52., ..., -90., -85.,   4.],\n",
       "        [-59., -50., -45., ..., -88., -87.,   4.]]))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_split(dataset, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c5cef40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e54b1aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4753b43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_node(split_feat, split_value):\n",
    "    node = {(split_feat,split_value): ({},{})}\n",
    "    return node\n",
    "\n",
    "def make_leaf(data, classes):\n",
    "    N = len(data)\n",
    "    result =  np.argmax([len(data[data[:,-1] == label]) for label in classes])/N\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "62243866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_leaf(data, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "dd08ad5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decision_tree_learning(dataset, depth):\n",
    "    feat, thresh = find_split(dataset)\n",
    "    node = node(feat, thresh)\n",
    "    \n",
    "    node[(feat_thresh)] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a4e18d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee490288",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
